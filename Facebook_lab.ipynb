{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lab 1 - Analyzing Facebook data\n",
    "\n",
    "This notebook guides you through process of loading and analyzing real (but anonymized) Facebook data. The two goals for the notebook are to give you a better idea of the workflow for doing data analysis with Python and to introduce you to a \"big data\" type data source. In particular, we'll focus on networks because they go hand-in-hand with the big data movement. We aren't using your own live Facebook data because the new Facebook API (system for accessing their databases) much more aggressively limits what data we can get. Yay for privacy! Too bad for us big data nerds:(\n",
    "\n",
    "In order to be able to use this notebook, you need the Facebook_Lab.py file and the data files, named #_friend_data.json and #_general_data.csv (where # is some number between 1 and 5). You should have got these files when you downloaded the folder this notebook is in. If you are getting import or file not found errors, make sure you have those files.\n",
    "<br><br>\n",
    "\n",
    "This is the structure of this session:\n",
    "    1. Quick intro in the JSON file format\n",
    "    2. Super quick Facebook refresher \n",
    "    3. Loading JSON formatted Facebook data\n",
    "    4. Putting the data into a PANDAS dataframe\n",
    "    5. Plotting networks\n",
    "    6. Measuring networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few things about this notebook\n",
    "\n",
    "* The module/package Facebook_Lab has functions that do a lot of behind the scenes processing. If you want to see the details, you should open up that file in a text editor or IDE.\n",
    "    <br><br>\n",
    "* There are occasionally snippets of code that are commented out with a hashtag (`#`) in front of them. Removing the hashtag and any extra spaces will make that code live as well. This is a convenient way to experiment with different options without having delete and rewrite lines of code all the time.\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Topic 1: the JSON format \n",
    "\n",
    "A common format for API data is the *JSON* (JavaScript Object Notation) format. A *JSON* formatted file is human-readable and ends with *.json*. At this point, the format's only meaningful connection to its namesake JavaScript is that it is built around the concept of *objects*, which is at the core of the object-oriented programming paradigm that Java popularized. This matters to us only in that thinking in terms of objects is helpful for a lot of Big Data.\n",
    "\n",
    "Consider a tweet:\n",
    "<blockquote class=\"twitter-tweet\" lang=\"en\"><p lang=\"en\" dir=\"ltr\">Warriors vs. Cavs. &#10;Steph vs. LeBron. &#10;&#10;See you June 4th. <a href=\"http://t.co/3ZjzzU4lkW\">pic.twitter.com/3ZjzzU4lkW</a></p>&mdash; NBA on ESPN (@ESPNNBA) <a href=\"https://twitter.com/ESPNNBA/status/603774381773434880\">May 28, 2015</a></blockquote> <script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "![img](http://pbs.twimg.com/tweet_video_thumb/CGEJBySUgAAFhD3.png)\n",
    "\n",
    "<br>\n",
    "In our daily lives, we view a tweet as a (very) short piece of text but there is a lot more to a tweet. Below is the JSON representation for the same tweet. \n",
    "<br><br>\n",
    "\n",
    "<code> {u'contributors': None,\n",
    "  u'coordinates': None,\n",
    "  u'created_at': u'Thu May 28 04:06:44 +0000 2015',\n",
    "  u'entities': {u'hashtags': [],\n",
    "   u'media': [{u'display_url': u'pic.twitter.com/3ZjzzU4lkW',\n",
    "     u'expanded_url': u'http://twitter.com/ESPNNBA/status/603774381773434880/photo/1',\n",
    "     u'id': 603773751327490048,\n",
    "     u'id_str': u'603773751327490048',\n",
    "     u'indices': [58, 80],\n",
    "     u'media_url': u'http://pbs.twimg.com/tweet_video_thumb/CGEJBySUgAAFhD3.png',\n",
    "     u'media_url_https': u'https://pbs.twimg.com/tweet_video_thumb/CGEJBySUgAAFhD3.png',\n",
    "     u'sizes': {u'large': {u'h': 512, u'resize': u'fit', u'w': 1024},\n",
    "      u'medium': {u'h': 300, u'resize': u'fit', u'w': 600},\n",
    "      u'small': {u'h': 170, u'resize': u'fit', u'w': 340},\n",
    "      u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}},\n",
    "     u'type': u'photo',\n",
    "     u'url': u'http://t.co/3ZjzzU4lkW'}],\n",
    "   u'symbols': [],\n",
    "   u'urls': [],\n",
    "   u'user_mentions': []},\n",
    "  u'extended_entities': {u'media': [{u'display_url': u'pic.twitter.com/3ZjzzU4lkW',\n",
    "     u'expanded_url': u'http://twitter.com/ESPNNBA/status/603774381773434880/photo/1',\n",
    "     u'id': 603773751327490048,\n",
    "     u'id_str': u'603773751327490048',\n",
    "     u'indices': [58, 80],\n",
    "     u'media_url': u'http://pbs.twimg.com/tweet_video_thumb/CGEJBySUgAAFhD3.png',\n",
    "     u'media_url_https': u'https://pbs.twimg.com/tweet_video_thumb/CGEJBySUgAAFhD3.png',\n",
    "     u'sizes': {u'large': {u'h': 512, u'resize': u'fit', u'w': 1024},\n",
    "      u'medium': {u'h': 300, u'resize': u'fit', u'w': 600},\n",
    "      u'small': {u'h': 170, u'resize': u'fit', u'w': 340},\n",
    "      u'thumb': {u'h': 150, u'resize': u'crop', u'w': 150}},\n",
    "     u'type': u'animated_gif',\n",
    "     u'url': u'http://t.co/3ZjzzU4lkW',\n",
    "     u'video_info': {u'aspect_ratio': [2, 1],\n",
    "      u'variants': [{u'bitrate': 0,\n",
    "        u'content_type': u'video/mp4',\n",
    "        u'url': u'https://pbs.twimg.com/tweet_video/CGEJBySUgAAFhD3.mp4'}]}}]},\n",
    "  u'favorite_count': 5088,\n",
    "  u'favorited': False,\n",
    "  u'geo': None,\n",
    "  u'id': 603774381773434880,\n",
    "  u'id_str': u'603774381773434880',\n",
    "  u'in_reply_to_screen_name': None,\n",
    "  u'in_reply_to_status_id': None,\n",
    "  u'in_reply_to_status_id_str': None,\n",
    "  u'in_reply_to_user_id': None,\n",
    "  u'in_reply_to_user_id_str': None,\n",
    "  u'lang': u'en',\n",
    "  u'place': None,\n",
    "  u'possibly_sensitive': False,\n",
    "  u'retweet_count': 5705,\n",
    "  u'retweeted': False,\n",
    "  u'source': u'<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    "  u'text': u'Warriors vs. Cavs. \\nSteph vs. LeBron. \\n\\nSee you June 4th. http://t.co/3ZjzzU4lkW',\n",
    "  u'truncated': False,\n",
    "  u'user': {u'contributors_enabled': False,\n",
    "   u'created_at': u'Tue Sep 15 18:37:13 +0000 2009',\n",
    "   u'default_profile': False,\n",
    "   u'default_profile_image': False,\n",
    "   u'description': u'Official Twitter account of the NBA on ESPN, home of the NBA Draft and the NBA Finals.',\n",
    "   u'entities': {u'description': {u'urls': []},\n",
    "    u'url': {u'urls': [{u'display_url': u'espn.go.com/nba/',\n",
    "       u'expanded_url': u'http://espn.go.com/nba/',\n",
    "       u'indices': [0, 22],\n",
    "       u'url': u'http://t.co/zIeRt15zFT'}]}},\n",
    "   u'favourites_count': 148,\n",
    "   u'follow_request_sent': False,\n",
    "   u'followers_count': 1503118,\n",
    "   u'following': False,\n",
    "   u'friends_count': 736,\n",
    "   u'geo_enabled': False,\n",
    "   u'id': 74518740,\n",
    "   u'id_str': u'74518740',\n",
    "   u'is_translation_enabled': False,\n",
    "   u'is_translator': False,\n",
    "   u'lang': u'en',\n",
    "   u'listed_count': 10181,\n",
    "   u'location': u'ESPN',\n",
    "   u'name': u'NBA on ESPN',\n",
    "   u'notifications': False,\n",
    "   u'profile_background_color': u'A15E00',\n",
    "   u'profile_background_image_url': u'http://pbs.twimg.com/profile_background_images/47166024/NBA_bg.jpg',\n",
    "   u'profile_background_image_url_https': u'https://pbs.twimg.com/profile_background_images/47166024/NBA_bg.jpg',\n",
    "   u'profile_background_tile': True,\n",
    "   u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/74518740/1429300276',\n",
    "   u'profile_image_url': u'http://pbs.twimg.com/profile_images/586012188302708736/B6IMM6eu_normal.jpg',\n",
    "   u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/586012188302708736/B6IMM6eu_normal.jpg',\n",
    "   u'profile_link_color': u'0000FF',\n",
    "   u'profile_sidebar_border_color': u'EEEEEE',\n",
    "   u'profile_sidebar_fill_color': u'E6EDF2',\n",
    "   u'profile_text_color': u'333333',\n",
    "   u'profile_use_background_image': True,\n",
    "   u'protected': False,\n",
    "   u'screen_name': u'ESPNNBA',\n",
    "   u'statuses_count': 45836,\n",
    "   u'time_zone': u'Quito',\n",
    "   u'url': u'http://t.co/zIeRt15zFT',\n",
    "   u'utc_offset': -18000,\n",
    "   u'verified': True}}</code>\n",
    "<br><br>\n",
    "\n",
    "As you can see, whatever a Tweet is, it is complex thing. (Can you even find the text of the tweet that actually shows up on your tweetbox?) What is clear is it exists in a set of relationships. And if there are relationships, there must be things being related. So let's just call those things *objects* to be stay generic as possible. \n",
    "\n",
    "In object-oriented programming (OO), objects are a collection of *fields* (or attributes) and *methods*, procedures to modify the fields. The essense of an *OO* program is the design of the objects and manipulation of them via methods. (OK, and a bunch of stuff we won't get into.) To do something with objects, we need to know a lot about them, but if we are just moving them around as we are when collecting data, we just need the names of the fields and their contents. So we need a file format that can keep track of attributes of objects.\n",
    "\n",
    "Maybe just a standard spreadsheet (.csv, .xls) you're probably intimately familiar with could work? A row for each observation can work fine for keeping track of an observation and its attributes, but what if an attribute is a reference to something other than another observation of the same type? That is, to another type of object? There is a good chance we'll want to know more about those other objects so we want it's attributes too. Unfortunately, a spreadsheet isn't very convenient for transporting that type of information. The JSON format can help us address this problem and that's why lots of data rich APIs use them.\n",
    "\n",
    "Going back the tweet above, you can see that this record of a single tweet contains references to lots of other objects, each with it's own attributes. They are indented and encased in curly brackets {}. Examples are the posting user, \"entities\", and urls.\n",
    "\n",
    "It's having this type of data that makes big data interesting\\* to social scientists IMAO. These data offer a \n",
    "chance to understand the rich, relational context of the observations. We can track them through time better too. I \n",
    "\n",
    "\\*Unless you just want a [large N sample to ensure significant (i.e. publishable) p-values](https://www.youtube.com/watch?v=0pQ3AQ8olEo) (see [Granger 1998](http://onlinelibrary.wiley.com/doi/10.1111/1467-9574.00084/abstract)). \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you continue doing big data research, you'll encounter other formats, but JSON is a good starting point. You'll have a chance to collect live Twitter data soon, but to first get you more familiar with Python and the general workflow, we'll start with some limited, but real Facebook data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "###Topic 2: Facebook data\n",
    "\n",
    "Facebook is a great big data source because it has a diverse user base and a variety of data types. Two months ago it was a fantastic resource for some introspective research about the shape and composition of your network, but they just changed the privacy settings of the API so that we can't get the data. Even the very cool Wolfram Alpha tool has [been shut down](http://company.wolfram.com/news/2015/wolframalpha-personal-analytics-for-facebook-last-chance-to-analyze-your-friend-network/).\n",
    "\n",
    "<br>\n",
    "\n",
    "Today we'll use some networks I saved (and anonymized) in order to practice loading JSON formatted data into a Pandas data structure so that we can run queries and produce results.\n",
    "The Facebook Restful API responds with JSON formatted data and I've cleaned the data up and stored them .json files. \n",
    "\n",
    "This is what a single entry looks like:\n",
    "\n",
    "<code>{\n",
    " \"gender\": \"female\", \n",
    " \"id\": 15, \n",
    " \"name\": \"RM\",\n",
    " \"mutuals\": \"[8, 29, 66, 75, 100, 139, 155, 160, 194, 218, 286, 299, 322]\",\n",
    " \"known from\": 4\n",
    "}</code>\n",
    "\n",
    "A typical JSON file will have lots of entries seperated by commas. If you want to see one, open up the file <code>1_data.json</code> in a text editor.\n",
    "\n",
    "\n",
    "Now let's go through this entry and explain the fields:\n",
    "\n",
    "- gender: The user specified gender. The possible values are male, female, or None (because Facebook doesn't require you to provide one.\n",
    "- id: A unique number identifying the user. 1 is saved for the user whose network we are looking at (called the ego in network science).\n",
    "- name: The initials of the user.\n",
    "- mutuals: The list of IDs for the friends this user has in common with the Ego (i.e. mutual friends).\n",
    "- known from: A categorical variable identifying where the Ego knows this user from\n",
    "\n",
    "This is only a sliver of the data fields Facebook used to provide (plus a custom variable [known from]), but we can do a lot with these once we have a bunch of them into Python's memory. Let's do that now.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "##Topic 3: Loading the Facebook data\n",
    "\n",
    "To get entries into memory, we'll use a very convenient Python module called <code>json</code>. Let's import it on the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>json</code> can encode Python data structures into JSON formatted text and visa versa. To do this file writing and reading, it makes use of Python's standard file I/O (input/output) tools. The next line uses the I/O function <code>open()</code> to open the given file in the read mode. This is because we used the \"r\" argument. If we want to be able to write, we'd use \"w\" to (over)write a new file or \"a\" to append to the end of an existing file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = open(\"1_data.json\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a reader (which I've named <code>reader</code>) attached to the file. The reader has functions (e.g. <code>reader.read()</code> and <code>reader.readline()</code>) that lets us read what is in the file. We don't use them here; instead we just pass the whole reader to the <code>json</code> module and it calls them as it. We let <code>json</code> read in the whole file on the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_data = json.load(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what json did with the data by asking the type of object <code>our_data</code> is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(our_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You know what we can do with a Python dictionary. Let's look at what keys are in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(our_data['users'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it's pretty boring. That's because our .json file must have only one kind of object in it. Let's see what's in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_data[\"users\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_data[\"users\"][-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many items are in this list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(our_data[\"users\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what data type is are the elements in the list? Just grab one and check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(our_data[\"users\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so the <code>json.load()</code> method has given use a dictionary with a list of dictionaries inside of it. (Python is great at nesting data types like this.) An item in the list is a dictionary of attribute/value combinations for each object in the file. The use of a dictionary makes sense because it corresponds closely to the structure of the JSON format. But what to do with this list of dictionaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Topic 4: Moving data into a Pandas dataframe\n",
    "\n",
    "We now have our data into the computer's memory where we can analyse it. We could leave it in the list called <code>our_data</code> for our analyses but these Python types weren't designed for a lot of the manipulations and queries we could imagine running. Instead, we'll make use of Pandas, a Python module for data analysis. It features some easy I/O functions so it can serve as a makeshift database for smaller projects. Let get started with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core tools of Pandas are two data structure objects called <code>Series</code> and <code>Dataframe</code>. These let us package up data that is already in Python objects in something that allows us to do analysis directly. Details [can be found here](http://http://pandas.pydata.org/), but for now we'll focus on just on what's necessary to construct a Dataframe.\n",
    "\n",
    "A DataFrame is designed to be populated all at once. You can append DataFrames together easily when you need to add data to an existing DataFrame, but single observations are generally not loaded directly into the DataFrames.\n",
    "\n",
    "When we are creating a new dataframe, we can provide a list that specifies the data elements (attributes) for the yet-empty dataframe. But we don't have to do that from the get-go! We could just start loading in data, adding the appropriate indices as we go, but because we know what attributes our data have, we'll create a dataframe with an column header. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attribute_names = [\"id\", \"gender\", \"name\", \"known from\", \"mutuals\"]\n",
    "our_df = pd.DataFrame(columns=attribute_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the \"shape\" of our dataframe by looking at its shape field. It should have 0 rows and 5 columns because we've only supplied the header. (Pandas seems to be pretty agnostic about how we orient the data, but we'll stick with the traditional rows-as-observations orientation for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has some nice tools for very quickly parsing data from csv and json into a DataFrame, but because you all are likely to have ongoing or Python-based data collection, we'll build our DataFrame step-by-step. Let's look at what we have so far by running the next line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next three cells show you what the basic task is. We create Series objects for each observation (user) and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series1 = pd.Series([1,1,1,1,1], index=[\"id\", \"gender\", \"name\", \"known from\", \"mutuals\"], name=1)\n",
    "series2 = pd.Series([2,2,2,2,2], index=[\"id\", \"gender\", \"name\", \"known from\", \"mutuals\"], name=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_observations = [series1, series2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_df.append(list_of_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that was easy enough. So now we need to figure out how to get our JSON data into series. It turns out, that isn't too hard. Because the observation is in a dictionary, we can use the <code>keys()</code> and <code>values()</code> methods to get the basis information. Note that each of those methods returns a list that can be given to the Series constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_data['users'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_data['users'][0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_series = pd.Series(our_data['users'][0].values(), index=our_data['users'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_df = our_df.append([example_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't bad at all! Now let's do some looping to read all the observations into a list of Series that we can load into the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_df = pd.DataFrame(columns=attribute_names)\n",
    "all_observations = [] #an empty list\n",
    "for user in our_data['users']:\n",
    "    a_series = pd.Series(user.values(), index=user.keys(), name=user['id'])\n",
    "    all_observations.append(a_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_df = our_df.append(all_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_df[\"mutuals\"][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 5: Plotting the network\n",
    "\n",
    "Because this lesson is getting to long and because we'd have to do some more technical things, we're going to load the data another way and skip forward to plotting the network(s).\n",
    "\n",
    "Run the lines below to load into memory a Facebook network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Facebook_Lab as fb\n",
    "graph = fb.FBgraph(\"1\")\n",
    "graph.load_data(file_name=\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a powerful module called networkX for our network analysis. As you can see after running the following code, it's not very good at drawing. For that, we'll use something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "#nx.draw_random(graph.mynet)\n",
    "spring = nx.spring_layout(graph.mynet, iterations=2)\n",
    "nx.draw(graph.mynet, spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better graphics\n",
    "Now we'll use another method of drawing. It makes use of JavaScript to make a dynamic webpage (just like this notebook). It's not perfect for this application because it requires too many calculations for labtops, but the results are still pretty cool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.draw_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This command produced a data file that can be seen by going to the Social Dynamics folder and opening up the file named \"JSON_network.html\" This page contains a script that runs an algorithm that visualizes the data dynamically.\n",
    "\n",
    "<p>It might look like some nodes are farther away from you than others, but that is not the case because they all have a tie to you. Rather, an algorithm is moving everyone around to group people together. \n",
    "\n",
    "The algorithm is a physics simulator running in the browser window so that you can move nodes around and inspect elements.</p>\n",
    "<p> At first the nodes and links will be flying around space in a crazy way, but \"gravity\" and other forces will eventually get it to settle down. At that point you can do the following things:</p>\n",
    "\n",
    "- Click and drag to fix a node's position.\n",
    "- Hover over nodes and ties to see names and friend counts.\n",
    "- Double click on nodes to \"unstick\" them.\n",
    "- Stop/start the algorithm with the buttons in the top left corner.\n",
    "\n",
    "This plotter can render tie weights visually and color strong ties blue if you have defined those attributes for all nodes. To get them to render, set arguments *strong* or *weight* equal to true as shown in the commented out code below.\n",
    "\n",
    "The chief benefit of this graphing method is that it allows you to literally pull the network a part to better see structure. For large networks the display and responses will probably be choppy at the beginning but as the physical forces \"cool\" over time, the structure will stablize and graphics will catch up. You can also plot the network without you node using the argument *withme=False*. **This version of the network is much clearer and your processer might probably have an easier time with it. I highly recommend experimenting with this option.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graph.draw_network()\n",
    "#graph.draw_network(strong=True, weight=True)\n",
    "graph.draw_network(withme=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Topic 6: Analyzing the network\n",
    "\n",
    "We can use some builtin commands to do some basic measurements on the network\n",
    "\n",
    "- You can look at the clustering coefficients for nodes using the *clustering( )* command. The command takes a *group* argument that returns clustering coefficients for just the specified group from your social contexts list (the number, not the name). Without the group argument it returns the whole network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.clustering() #whole network\n",
    "#graph.get_average_clustering(graph.clustering())\n",
    "#graph.clustering(1) #just group one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graph.count_components() #the number of components in the graph\n",
    "graph.count_components(withme=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graph.diameter()\n",
    "graph.diameter(withme=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.degree(graph.name_to_id(\"#a_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.degree_centrality()\n",
    "#graph.degree_centrality(withme=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.closeness_centrality()\n",
    "#graph.closeness_centrality(withme=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.betweenness_centrality()\n",
    "#graph.betweenness_centrality(withme=False)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.eigenvector_centrality(iterations=500,withme=False) # may fail with too few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = graph.associativity_by_attribute(\"gender\") #any attribute you have coded for will work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = graph.clustering_by_attribute(\"gender\") # any attribute you have coded for will work here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = graph.clustering_by_attribute_summary(\"gender\") #summary means average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
